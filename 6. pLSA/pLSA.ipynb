{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import codecs\n",
    "import regex as re\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from collections import defaultdict\n",
    "from pylab import random\n",
    "import pandas as pd\n",
    "from scipy.stats.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " N - количество документов\n",
    " M - длина словаря слов\n",
    " К - кол-во тематик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepE():\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            denominator = 0\n",
    "            for k in range(K):\n",
    "                p[i, j, k] = fi[j, k] * theta[k, i]\n",
    "                denominator += p[i, j, k]\n",
    "            if denominator == 0:\n",
    "                for k in range(0, K):\n",
    "                    p[i, j, k] = 0\n",
    "            else:\n",
    "                for k in range(0, K):\n",
    "                    p[i, j, k] /= denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepM():\n",
    "    # update fi\n",
    "    for k in range(0, K):\n",
    "        denominator = 0\n",
    "        for j in range(0, M):\n",
    "            fi[j, k] = 0\n",
    "            for i in range(0, N):\n",
    "                fi[j, k] += X[i, j] * p[i, j, k]\n",
    "            denominator += fi[j, k]\n",
    "        if denominator == 0:\n",
    "            for j in range(0, M):\n",
    "                fi[j, k] = 1.0 / M\n",
    "        else:\n",
    "            for j in range(0, M):\n",
    "                fi[j, k] /= denominator\n",
    "    # update theta\n",
    "    for i in range(0, N):\n",
    "        for k in range(0, K):\n",
    "            theta[k,i] = 0\n",
    "            denominator = 0\n",
    "            for j in range(0, M):\n",
    "                theta[k,i] += X[i, j] * p[i, j, k]\n",
    "                denominator += X[i,j];\n",
    "            if denominator == 0:\n",
    "                theta[k,i] = 1.0 / K\n",
    "            else:\n",
    "                theta[k,i] /= denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = codecs.open('datasets2.txt', 'r', 'utf-8')\n",
    "documents = [document.strip() for document in file] \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = codecs.open('sw.txt', 'r', 'utf-8')\n",
    "stopwords = [line.strip() for line in file] \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathCV = 'example3/' #Computer vision articles\n",
    "texts = []\n",
    "#получаем каждый документ и создаем корпус\n",
    "for i in range(10):\n",
    "    fileObj = codecs.open( pathCV + str(i)+'.txt', \"r\", \"utf_8_sig\" )\n",
    "    text = fileObj.read() # или читайте по строке\n",
    "    texts.append(text)\n",
    "    fileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return re.sub(r'\\p{P}+', \"\", text)\n",
    "def change_num(text):\n",
    "    return re.sub(r'[\\d]+', \"1\", text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "def lemmatization(text):\n",
    "    tx = change_num(remove_punctuation(text.lower()))\n",
    "    doc = nlp(tx)\n",
    "    return [token.lemma_ for token in doc if token.lemma_ not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lem = [lemmatization(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(X_lem)\n",
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3761"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = defaultdict(int)#\n",
    "count_words =[]\n",
    "for doc in X_lem:\n",
    "    count_word = defaultdict(int)\n",
    "    for word in doc:\n",
    "        tokens[word] += 1\n",
    "        count_word[word] = +1\n",
    "    count_words.append(count_word)\n",
    "M = len(tokens)\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for key in tokens.keys():\n",
    "    words.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros([N, M])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j,word in enumerate(words):\n",
    "    for i,doc in enumerate(X_lem):\n",
    "        X[i,j] = count_words[i][word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3761)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20    # number of topic\n",
    "maxIteration = 20\n",
    "threshold = 10.0\n",
    "topicWordsNum = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fi = random([M, K])\n",
    "theta = random([K, N])\n",
    "p = np.zeros([N, M, K])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeParameters():\n",
    "    for i in range(0, N):\n",
    "        normalization = sum(theta[:, i])\n",
    "        for j in range(0, K):\n",
    "            theta[j, i] /= normalization\n",
    "\n",
    "    for i in range(0, K):\n",
    "        normalization = sum(fi[:, i])\n",
    "        for j in range(0, M):\n",
    "            fi[j, i] /= normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogLikelihood():\n",
    "    loglikelihood = 0\n",
    "    for i in range(0, N):\n",
    "        for j in range(0, M):\n",
    "            tmp = 0\n",
    "            for k in range(0, K):\n",
    "                tmp += fi[j, k] * theta[k, i]\n",
    "            if tmp > 0:\n",
    "                loglikelihood += X[i, j] * np.log(tmp)\n",
    "    return loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68542732, 0.4922167 , 0.26394482, ..., 0.54459375, 0.8138456 ,\n",
       "        0.36531612],\n",
       "       [0.45936685, 0.71825421, 0.78572027, ..., 0.0989575 , 0.18335985,\n",
       "        0.79688551],\n",
       "       [0.23672602, 0.64880209, 0.44491489, ..., 0.22277439, 0.02264028,\n",
       "        0.28760738],\n",
       "       ...,\n",
       "       [0.42445104, 0.97934239, 0.7972429 , ..., 0.60461378, 0.78930225,\n",
       "        0.56032957],\n",
       "       [0.1814033 , 0.44007232, 0.04433484, ..., 0.37721344, 0.38509809,\n",
       "        0.24969651],\n",
       "       [0.48519889, 0.91684516, 0.2494058 , ..., 0.9056238 , 0.12780078,\n",
       "        0.50029401]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializeParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.62268537e-04, 2.62086261e-04, 1.41716571e-04, ...,\n",
       "        2.96284512e-04, 4.33684911e-04, 1.95489281e-04],\n",
       "       [2.42788914e-04, 3.82442451e-04, 4.21866898e-04, ...,\n",
       "        5.38375139e-05, 9.77094438e-05, 4.26432256e-04],\n",
       "       [1.25116679e-04, 3.45461896e-04, 2.38882552e-04, ...,\n",
       "        1.21199706e-04, 1.20646344e-05, 1.53905500e-04],\n",
       "       ...,\n",
       "       [2.24334884e-04, 5.21461761e-04, 4.28053598e-04, ...,\n",
       "        3.28938223e-04, 4.20606161e-04, 2.99845586e-04],\n",
       "       [9.58769895e-05, 2.34321409e-04, 2.38041461e-05, ...,\n",
       "        2.05221785e-04, 2.05212424e-04, 1.33618499e-04],\n",
       "       [2.56441911e-04, 4.88184414e-04, 1.33910318e-04, ...,\n",
       "        4.92701777e-04, 6.81029274e-05, 2.67719141e-04]])"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2020-05-30 00:39:26 ]  1  iteration   -45456.855617596986\n",
      "[ 2020-05-30 00:39:32 ]  2  iteration   -44734.068852379714\n",
      "[ 2020-05-30 00:39:37 ]  3  iteration   -43625.7708957977\n",
      "[ 2020-05-30 00:39:42 ]  4  iteration   -42148.41588392831\n",
      "[ 2020-05-30 00:39:47 ]  5  iteration   -40613.81751249084\n",
      "[ 2020-05-30 00:39:53 ]  6  iteration   -39402.59314825921\n",
      "[ 2020-05-30 00:39:58 ]  7  iteration   -38603.67059116329\n",
      "[ 2020-05-30 00:40:03 ]  8  iteration   -38136.39101040347\n",
      "[ 2020-05-30 00:40:08 ]  9  iteration   -37889.8364458977\n",
      "[ 2020-05-30 00:40:14 ]  10  iteration   -37759.53372470167\n",
      "[ 2020-05-30 00:40:19 ]  11  iteration   -37680.345769979234\n",
      "[ 2020-05-30 00:40:24 ]  12  iteration   -37621.95245226537\n",
      "[ 2020-05-30 00:40:29 ]  13  iteration   -37562.226523812235\n",
      "[ 2020-05-30 00:40:35 ]  14  iteration   -37479.415076305275\n",
      "[ 2020-05-30 00:40:40 ]  15  iteration   -37374.27558784685\n",
      "[ 2020-05-30 00:40:45 ]  16  iteration   -37292.19691217964\n",
      "[ 2020-05-30 00:40:50 ]  17  iteration   -37245.5136855339\n",
      "[ 2020-05-30 00:40:56 ]  18  iteration   -37212.36904291205\n",
      "[ 2020-05-30 00:41:01 ]  19  iteration   -37195.85609848185\n",
      "[ 2020-05-30 00:41:06 ]  20  iteration   -37189.416816733945\n"
     ]
    }
   ],
   "source": [
    "oldLoglikelihood = 1\n",
    "newLoglikelihood = 1\n",
    "for i in range(0, maxIteration):\n",
    "    stepE()\n",
    "    stepM()\n",
    "    newLoglikelihood = LogLikelihood()\n",
    "    print(\"[\", time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())), \"] \", i+1, \" iteration  \", str(newLoglikelihood))\n",
    "    if(oldLoglikelihood != 1 and newLoglikelihood - oldLoglikelihood < threshold):\n",
    "        break\n",
    "    oldLoglikelihood = newLoglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3761, 20)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops_w =[]\n",
    "for i in range(0, K):\n",
    "    topicword = []\n",
    "    ids = fi[:, i].argsort()\n",
    "    for j in ids:\n",
    "        topicword.insert(0, words[j])\n",
    "    tmp = ''\n",
    "    for word in topicword[0:min(topicWordsNum, len(topicword))]:\n",
    "        tmp += word + ' '\n",
    "    tops_w.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['situ conclude promote interaction reduction trigger strong induction comprise wellensiek ',\n",
       " 'wine birth party multicellular improve herbal cornflower generation oxygen actively ',\n",
       " 'explain oak wildflower botanist reproductive solanum mountain dispersal greek pond ',\n",
       " 'lake freshwater atmosphere spell lemnaceae unrelated store size wolffia burn ',\n",
       " 'pattern occur molecular lily floral pollen insect female nectar wind ',\n",
       " 'represent wide success taxon define change environment fashion lack wing ',\n",
       " 'feed blossom cluster family sunflow tiny central top attractive citriodora ',\n",
       " 'spiny surround approach gardens fall grassland typical bed acre meadow ',\n",
       " 'choose mix create inspire couple learn design period nature thistle ',\n",
       " 'biennial establish free typical size endosporic start chiropterophily common salverform ',\n",
       " 'simply identification depend dry density provide mark condition characterize shortlived ',\n",
       " 'visit foster lend nourish behold march predate word pond advantage ',\n",
       " 'primordia reference induce mutant identity pathway prominent directly gene madsbox ',\n",
       " 'ritual century rich respiratory food white ancient beauty symbol scent ',\n",
       " 'set dragonfly notion male produce ago arrest milk lily reproductive ',\n",
       " 'specialized guide ritual biological gland unisexual population rich sexual sex ',\n",
       " 'technically associates recordbreaker review bee spot african organ longifolia photosynthetic ',\n",
       " 'volume exploit air assess conceivable estimate triangular pave prospect uncertainty ',\n",
       " 'choose remove mix delicate provide ground week cool yellow scatter ',\n",
       " 'fall style cycle greatly lack term family monoecious snapdragon surround ']"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tops_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('wordsim_similarity_goldstandard.txt',sep='\\t', names=['word1','word2','sim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = data['word1'].values\n",
    "word2 = data['word2'].values\n",
    "scores = data['sim'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs = []\n",
    "for k,w in enumerate(zip(word1,word2)):\n",
    "    if (w[0] in words) and (w[1] in words):\n",
    "        indexs.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos(A,B):\n",
    "    SumA = 0 \n",
    "    SumB = 0\n",
    "    SumAB = 0\n",
    "    for i in range(len(A)):\n",
    "        SumAB += A[i]*B[i]\n",
    "        SumA += A[i]**2\n",
    "        SumB += B[i]**2\n",
    "    return SumAB/(np.sqrt(SumA)*np.sqrt(SumB))\n",
    "\n",
    "def jac(A,B):\n",
    "\n",
    "    SumA = 0 \n",
    "    SumB = 0\n",
    "    for i in range(len(A)):\n",
    "        SumA += min(A[i],B[i])\n",
    "        SumB += max(A[i],B[i])\n",
    "    return SumA/SumB\n",
    "\n",
    "def KL(A,B):\n",
    "    Sum = 0\n",
    "    for i in range (len(A)):\n",
    "        if (A[i] != 0) and B[i] != 0:\n",
    "            Sum += A[i] * np.log(A[i]/B[i])\n",
    "    return Sum\n",
    "\n",
    "def JS(A,B):\n",
    "    AB = [(u[0]+u[1])/2 for u in zip(A,B)]\n",
    "    return (KL(A,AB)+KL(B,AB))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.029105132110236312, -0.021953617525467078, -0.31042686098720423, 0.06050863208558216)]\n"
     ]
    }
   ],
   "source": [
    "C =[]\n",
    "cos_dist = []\n",
    "jac_dist = []\n",
    "KL_dist = []\n",
    "JS_dist = []\n",
    "SC = []\n",
    "for j in indexs:\n",
    "    index_w1 = words.index(word1[j])\n",
    "    index_w2 = words.index(word2[j])\n",
    "    A = fi[index_w1]\n",
    "    B = fi[index_w2]\n",
    "    \n",
    "    cos_dist.append(cos(A,B))\n",
    "    jac_dist.append(jac(A,B))\n",
    "    KL_dist.append(KL(A,B))\n",
    "    JS_dist.append(JS(A,B))\n",
    "    SC.append(scores[j])\n",
    "    \n",
    "C.append((pearsonr(cos_dist,SC)[0],pearsonr(jac_dist,SC)[0],pearsonr(KL_dist,SC)[0],pearsonr(JS_dist,SC)[0]))\n",
    "print(C)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
