{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "import math\n",
    "import nltk\n",
    "import collections\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Токенизация текста\n",
    "def tokenization(text):\n",
    "    \n",
    "    doc = re.split(r' *[\\;\\:\\—\\<\\>\\\\\\\"\\.\\,\\!\\?\\&\\=\\+\\(\\)\\{\\}\\[\\]\\r\\n\\t\\« \\»\\“\\”\\„\\/\\d ]', text) \n",
    "    tokens = []\n",
    "    for token in doc: \n",
    "        if token != '':\n",
    "            tokens.append(token.lower())        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#токенизируем каждый текст в корпусе\n",
    "def tokenization_corpus(corpus):\n",
    "    corpus_tokins = []\n",
    "    for text in corpus:\n",
    "        corpus_tokins.append(tokenization(text))\n",
    "    return corpus_tokins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем все токены в корпусе\n",
    "def all_corpus_tokens(corpus_tokens):\n",
    "    all_tokens =[]\n",
    "    for text in corpus_tokens:\n",
    "        for word in text:\n",
    "            all_tokens.append(word)\n",
    "    return all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#стемминг и лемматизация для одного текста\n",
    "def stem_lem(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(lemmatizer.lemmatize(word)) for word in tokens]\n",
    "    #return [stemmer.stem(word) for word in tokens]\n",
    "    #return [lemmatizer.lemmatize(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#стемминг и лемматизация для корпуса текстов\n",
    "def stem_lem_corpus(corpus):\n",
    "    u_corp = []\n",
    "    for tokens in corpus:\n",
    "        u_corp.append(stem_lem(tokens))\n",
    "    return u_corp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#считаем P(wi)\n",
    "def  Pw(tokens):\n",
    "    tf_countter = collections.Counter(tokens)\n",
    "    for i in tf_countter:\n",
    "        tf_countter[i] = tf_countter[i]/len(tokens)\n",
    "    return tf_countter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathCV = './../3. TF-IDF/example1/' #Computer vision articles\n",
    "texts = []\n",
    "#получаем каждый документ и создаем корпус\n",
    "for i in range(3):\n",
    "    fileObj = codecs.open( pathCV + str(i)+'.txt', \"r\", \"utf_8_sig\" )\n",
    "    text = fileObj.read() # или читайте по строке\n",
    "    texts.append(text)\n",
    "    fileObj.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_corp = tokenization_corpus(texts)\n",
    "all_tokens = all_corpus_tokens(tokens_corp)\n",
    "    \n",
    "    \n",
    "#Лемматизация и стемминг\n",
    "st_lm_all_tokkens = stem_lem(all_tokens)\n",
    "st_lm_tokens_corp = stem_lem_corpus(tokens_corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_wi_wj(corpus,tokens,w_size):\n",
    "    matrix_ww = np.zeros((len(tokens),len(tokens)))\n",
    "    size_corpus = len(corpus)\n",
    "    for i in range(size_corpus):\n",
    "        left_border = 0 if i-w_size < 0 else i-w_size\n",
    "        right_border = size_corpus if i+w_size > size_corpus else i+w_size\n",
    "        #index_i_matrix = tokens.index(corpus[i]) \n",
    "        for j in np.arange(left_border,right_border):\n",
    "            index_j_matrix = tokens.index(corpus[j])\n",
    "            for k in np.arange(j+1,right_border):\n",
    "                index_k_matrix = tokens.index(corpus[k])\n",
    "                matrix_ww[index_k_matrix,index_j_matrix] += 1/size_corpus\n",
    "                matrix_ww[index_j_matrix,index_k_matrix] += 1/size_corpus\n",
    "                \n",
    "    return matrix_ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_new = []\n",
    "for text in st_lm_tokens_corp:\n",
    "    corpus_new.extend(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = list(set(st_lm_all_tokkens))\n",
    "unique.index('vision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9198"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_wi_wj = p_wi_wj(corpus_new,unique,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1474, 1474)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_wi_wj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9198"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter_wi = Pw(st_lm_all_tokkens)\n",
    "len(st_lm_all_tokkens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmi(matrix_wi_wj,counter_wi,unique):\n",
    "    size = len(unique)\n",
    "    matrix_ppmi = np.zeros((size,size))\n",
    "    for i in range(size):\n",
    "        word_i = unique[i]\n",
    "        for j in range(size):\n",
    "            word_j = unique[j]\n",
    "            if matrix_wi_wj[i,j] == 0:\n",
    "                matrix_ppmi[i,j] = 0\n",
    "            else:\n",
    "                matrix_ppmi[i,j] = np.log(matrix_wi_wj[i,j]/(counter_wi[word_i]*counter_wi[word_j]))#PMI=P(Wi,Wj)/(P(Wi)*P(Wj))\n",
    "    return matrix_ppmi     \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_ppmi = ppmi(matrix_wi_wj,counter_wi,unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_ppmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1204,685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.31065378406395444\n",
      "-0.7147742252205117\n",
      "-0.21389762717099223\n",
      "-0.21389762717099223\n",
      "-0.19195870129835865\n",
      "-0.31065378406395444\n",
      "-0.7147742252205117\n",
      "-0.3158294904223601\n",
      "-0.19195870129835865\n"
     ]
    }
   ],
   "source": [
    "for it in matrix_ppmi:\n",
    "    for ti in it:\n",
    "        if ti<0:\n",
    "            print(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.21532879455420809\n",
      "-0.49544373894851707\n",
      "-0.1482625372020356\n",
      "-0.1482625372020356\n",
      "-0.13305563258890601\n",
      "-0.21532879455420809\n",
      "-0.49544373894851707\n",
      "-0.21891632082394313\n",
      "-0.13305563258890601\n"
     ]
    }
   ],
   "source": [
    "for it in matrix_ppmi:\n",
    "    for ti in it:\n",
    "        if ti<0:\n",
    "            print(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09502065666449228"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_wi_wj[1204,685]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09502065666449228"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "874/9198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_m = cosine_similarity(matrix_ppmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxn = 0\n",
    "x = 0\n",
    "y = 0\n",
    "for i,simpl in enumerate(cs_m):\n",
    "    for j,ti in enumerate(simpl):\n",
    "        if ti>maxn and ti<1-0.001:\n",
    "            x = i\n",
    "            y = j\n",
    "            maxn = ti\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(883, 974, 0.8340186277625213)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,maxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('surveil', 'realis')"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique[882],unique[973]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
