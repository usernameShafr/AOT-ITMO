{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "import math\n",
    "import collections\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(text):\n",
    "    \n",
    "    doc = re.split(r' *[\\;\\:\\—\\<\\>\\\\\\\"\\.\\,\\!\\?\\&\\=\\+\\(\\)\\{\\}\\[\\]\\r\\n\\t\\« \\»\\“\\”\\„\\/\\d ]', text) \n",
    "    tokens = []\n",
    "    for token in doc: \n",
    "        if token != '':\n",
    "            tokens.append(token.lower())        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization_corpus(corpus):\n",
    "    corpus_tokins = []\n",
    "    for text in corpus:\n",
    "        corpus_tokins.append(tokenization(text))\n",
    "        #corpus_tokins.append([porter.stem(i.lower()) for i in tokenization(text) if i.lower() not in stop_words] )\n",
    "    return corpus_tokins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ua = 'Кожна людина має право на освіту. Освіта повинна бути безплатною, хоча б початкова і загальна. Початкова освіта повинна бути обовязковою. Технічна і професійна освіта повинна бути загальнодоступною, а вища освіта повинна бути однаково доступною для всіх на основі здібностей кожного.Освіта повинна бути спрямована на повний розвиток людської особи і збільшення поваги до прав людини і основних свобод. Освіта повинна сприяти взаєморозумінню, терпимості і дружбі між усіма народами, расовими, або релігійними групами і повинна сприяти діяльності Організації Обєднаних Націй по підтриманню миру.Батьки мають право пріоритету у виборі виду освіти для своїх малолітніх дітей.'\n",
    "text_ru = 'Такому жанру как статья присуща ширина практических обобщений, глубокий анализ фактов и явлений, четкая социальная направленность[источник не указан 3907 дней]. В статье автор рассматривает отдельные ситуации как часть более широкого явления. Автор аргументированно пишет о своей точке зрения.В статье выражается развернутая обстоятельная аргументированная концепция автора или редакции по поводу актуальной социологической проблемы. Также в статье журналист обязательно должен интерпретировать факты (это могут быть цифры, дополнительная информация, которая будет правильно расставлять акценты и ярко раскрывать суть вопроса).Отличительным аспектом статьи является её готовность. Если подготавливаемый материал так и не был опубликован (не вышел в тираж, не получил распространения), то такой труд относить к статье некорректно. Скорее всего данную работу можно назвать черновиком или заготовкой. Поэтому целью любой статьи является распространение содержащейся в ней информации.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNgrams(tokens,n):\n",
    "    count_ngram = defaultdict(int)\n",
    "    for token in tokens:\n",
    "        if n <= len(token):\n",
    "            for i in range(len(token)-n+1):\n",
    "                count_ngram[token[i:i+n]] +=1\n",
    "    return count_ngram            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPr(tokens,n):\n",
    "    sum_ru =0 \n",
    "    sum_ua = 0\n",
    "    sum_be = 0\n",
    "    for token in tokens:\n",
    "        if n <= len(token):\n",
    "            for i in range(len(token)-n+1):\n",
    "                sum_ru += tt_ru[token[i:i+n]]/len(tokens_ru)\n",
    "                sum_ua += tt_ua[token[i:i+n]]/len(tokens_ua) \n",
    "                sum_be += tt_be[token[i:i+n]]/len(tokens_be) \n",
    "    return sum_ru,sum_ua,sum_be            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ua_test = 'Кожна людина має право вільно брати участь у культурному житті суспільства, втішатися мистецтвом, брати участь у науковому прогресі і користуватися його благами.'\n",
    "tokens_ua_test = tokenization(text_ua_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_texts(path,n):\n",
    "    texts = []\n",
    "    #получаем каждый документ и создаем корпус\n",
    "    for i in range(n):\n",
    "        fileObj = codecs.open( path + str(i)+'.txt', \"r\", \"utf_8_sig\" )\n",
    "        text = fileObj.read() \n",
    "        texts.append(text)\n",
    "        fileObj.close()\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_corpus_tokens(corpus_tokens):\n",
    "    all_tokens =[]\n",
    "    for text in corpus_tokens:\n",
    "        for word in text:\n",
    "            all_tokens.append(word)\n",
    "    return all_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ru = './train/ru/'\n",
    "path_ua = './train/ua/'\n",
    "path_be = './train/be/'\n",
    "texts_ru = get_texts(path_ru,8)\n",
    "texts_ua = get_texts(path_ua,8)\n",
    "texts_be = get_texts(path_be,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_ru = tokenization_corpus(texts_ru)\n",
    "tokens_ua = tokenization_corpus(texts_ua)\n",
    "tokens_be = tokenization_corpus(texts_be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_ru = all_corpus_tokens(tokens_ru)\n",
    "tokens_ua = all_corpus_tokens(tokens_ua)\n",
    "tokens_be = all_corpus_tokens(tokens_be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8070, 10548, 8146)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens_ru),len(tokens_ua),len(tokens_be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(answers):\n",
    "    zeros = -1\n",
    "    index = 0\n",
    "    for i in range(len(answers)):\n",
    "        if answers[i] > zeros:\n",
    "            zeros = answers[i]\n",
    "            index = i\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "k =3\n",
    "tt_ua = getNgrams(tokens_ua,k)\n",
    "tt_ru = getNgrams(tokens_ru,k)\n",
    "tt_be = getNgrams(tokens_be,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4069, 4032, 3649)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tt_ru),len(tt_ua),len(tt_be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ru       0.00      0.00      0.00         1\n",
      "          ua       0.50      0.33      0.40         3\n",
      "          be       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.50         6\n",
      "   macro avg       0.50      0.44      0.47         6\n",
      "weighted avg       0.58      0.50      0.53         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report([1,2,0,1,2,1],[0,2,1,1,2,0],target_names=('ru','ua','be')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_be_test = './test/'\n",
    "texts_be_test = get_texts(path_be_test,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_be_test = tokenization_corpus(texts_be_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for text in tokens_be_test:\n",
    "    predicted.append(predict(getPr(text,k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [2]*8+[1]*8+[0]*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ru       1.00      1.00      1.00         8\n",
      "          ua       1.00      1.00      1.00         8\n",
      "          be       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        24\n",
      "   macro avg       1.00      1.00      1.00        24\n",
      "weighted avg       1.00      1.00      1.00        24\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,predicted,target_names=('ru','ua','be')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
